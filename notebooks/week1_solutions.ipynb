{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 - assignment solution\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "- Read the dataset `metabric_clinical_and_expression_data.csv` and store its summary statistics into a new variable called `metabric_summary`.\n",
    "- Just like the `.read_csv()` method allows reading data from a file, `pandas` provides a `.to_csv()` method to write `DataFrames` to files. Write your summary statistics object into a file called `metabric_summary.csv`. You can use `help(metabric.to_csv)` to get information on how to use this function.\n",
    "- Use the help information to modify the previous step so that you can generate a Tab Separated Value (TSV) file instead \n",
    "- Similarly, explore the method `to_excel()` to produce an excel spreadsheet containing summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Age_at_diagnosis</th>\n",
       "      <th>Survival_time</th>\n",
       "      <th>Survival_status</th>\n",
       "      <th>Vital_status</th>\n",
       "      <th>Chemotherapy</th>\n",
       "      <th>Radiotherapy</th>\n",
       "      <th>Tumour_size</th>\n",
       "      <th>Tumour_stage</th>\n",
       "      <th>...</th>\n",
       "      <th>Integrative_cluster</th>\n",
       "      <th>Mutation_count</th>\n",
       "      <th>ESR1</th>\n",
       "      <th>ERBB2</th>\n",
       "      <th>PGR</th>\n",
       "      <th>TP53</th>\n",
       "      <th>PIK3CA</th>\n",
       "      <th>GATA3</th>\n",
       "      <th>FOXA1</th>\n",
       "      <th>MLPH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1904</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904</td>\n",
       "      <td>1903</td>\n",
       "      <td>1904</td>\n",
       "      <td>1904</td>\n",
       "      <td>1884.000000</td>\n",
       "      <td>1403.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1904</td>\n",
       "      <td>1859.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>MB-0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DECEASED</td>\n",
       "      <td>Living</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1103</td>\n",
       "      <td>801</td>\n",
       "      <td>1508</td>\n",
       "      <td>1137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.643908</td>\n",
       "      <td>61.087054</td>\n",
       "      <td>125.121324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.238726</td>\n",
       "      <td>1.750535</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.697687</td>\n",
       "      <td>9.607824</td>\n",
       "      <td>10.765364</td>\n",
       "      <td>6.237203</td>\n",
       "      <td>6.197967</td>\n",
       "      <td>5.970097</td>\n",
       "      <td>9.502910</td>\n",
       "      <td>10.800526</td>\n",
       "      <td>11.362384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.228615</td>\n",
       "      <td>12.978711</td>\n",
       "      <td>76.334148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.160976</td>\n",
       "      <td>0.628999</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.058778</td>\n",
       "      <td>2.133827</td>\n",
       "      <td>1.357359</td>\n",
       "      <td>1.020871</td>\n",
       "      <td>0.401864</td>\n",
       "      <td>0.352549</td>\n",
       "      <td>1.502636</td>\n",
       "      <td>1.754282</td>\n",
       "      <td>1.687555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.930000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.217238</td>\n",
       "      <td>6.372949</td>\n",
       "      <td>4.860645</td>\n",
       "      <td>5.201128</td>\n",
       "      <td>5.158697</td>\n",
       "      <td>5.277722</td>\n",
       "      <td>5.184945</td>\n",
       "      <td>5.323652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.375000</td>\n",
       "      <td>60.825000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.092992</td>\n",
       "      <td>9.969681</td>\n",
       "      <td>5.408728</td>\n",
       "      <td>5.930335</td>\n",
       "      <td>5.735007</td>\n",
       "      <td>8.767954</td>\n",
       "      <td>10.829777</td>\n",
       "      <td>11.042871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>61.770000</td>\n",
       "      <td>115.616667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.252166</td>\n",
       "      <td>10.530301</td>\n",
       "      <td>5.877591</td>\n",
       "      <td>6.185873</td>\n",
       "      <td>5.938094</td>\n",
       "      <td>9.911805</td>\n",
       "      <td>11.367947</td>\n",
       "      <td>11.873967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>70.592500</td>\n",
       "      <td>184.716667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.268331</td>\n",
       "      <td>11.159306</td>\n",
       "      <td>6.899220</td>\n",
       "      <td>6.456987</td>\n",
       "      <td>6.148720</td>\n",
       "      <td>10.560220</td>\n",
       "      <td>11.779545</td>\n",
       "      <td>12.396317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>96.290000</td>\n",
       "      <td>355.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>13.265184</td>\n",
       "      <td>14.643900</td>\n",
       "      <td>9.932115</td>\n",
       "      <td>7.921411</td>\n",
       "      <td>8.708396</td>\n",
       "      <td>12.812082</td>\n",
       "      <td>13.127682</td>\n",
       "      <td>14.432001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_ID       Cohort  Age_at_diagnosis  Survival_time  \\\n",
       "count        1904  1904.000000       1904.000000    1904.000000   \n",
       "unique       1904          NaN               NaN            NaN   \n",
       "top       MB-0000          NaN               NaN            NaN   \n",
       "freq            1          NaN               NaN            NaN   \n",
       "mean          NaN     2.643908         61.087054     125.121324   \n",
       "std           NaN     1.228615         12.978711      76.334148   \n",
       "min           NaN     1.000000         21.930000       0.000000   \n",
       "25%           NaN     1.000000         51.375000      60.825000   \n",
       "50%           NaN     3.000000         61.770000     115.616667   \n",
       "75%           NaN     3.000000         70.592500     184.716667   \n",
       "max           NaN     5.000000         96.290000     355.200000   \n",
       "\n",
       "       Survival_status Vital_status Chemotherapy Radiotherapy  Tumour_size  \\\n",
       "count             1904         1903         1904         1904  1884.000000   \n",
       "unique               2            3            2            2          NaN   \n",
       "top           DECEASED       Living           NO          YES          NaN   \n",
       "freq              1103          801         1508         1137          NaN   \n",
       "mean               NaN          NaN          NaN          NaN    26.238726   \n",
       "std                NaN          NaN          NaN          NaN    15.160976   \n",
       "min                NaN          NaN          NaN          NaN     1.000000   \n",
       "25%                NaN          NaN          NaN          NaN    17.000000   \n",
       "50%                NaN          NaN          NaN          NaN    23.000000   \n",
       "75%                NaN          NaN          NaN          NaN    30.000000   \n",
       "max                NaN          NaN          NaN          NaN   182.000000   \n",
       "\n",
       "        Tumour_stage  ...  Integrative_cluster  Mutation_count         ESR1  \\\n",
       "count    1403.000000  ...                 1904     1859.000000  1904.000000   \n",
       "unique           NaN  ...                   11             NaN          NaN   \n",
       "top              NaN  ...                    8             NaN          NaN   \n",
       "freq             NaN  ...                  289             NaN          NaN   \n",
       "mean        1.750535  ...                  NaN        5.697687     9.607824   \n",
       "std         0.628999  ...                  NaN        4.058778     2.133827   \n",
       "min         0.000000  ...                  NaN        1.000000     5.217238   \n",
       "25%         1.000000  ...                  NaN        3.000000     8.092992   \n",
       "50%         2.000000  ...                  NaN        5.000000    10.252166   \n",
       "75%         2.000000  ...                  NaN        7.000000    11.268331   \n",
       "max         4.000000  ...                  NaN       80.000000    13.265184   \n",
       "\n",
       "              ERBB2          PGR         TP53       PIK3CA        GATA3  \\\n",
       "count   1904.000000  1904.000000  1904.000000  1904.000000  1904.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      10.765364     6.237203     6.197967     5.970097     9.502910   \n",
       "std        1.357359     1.020871     0.401864     0.352549     1.502636   \n",
       "min        6.372949     4.860645     5.201128     5.158697     5.277722   \n",
       "25%        9.969681     5.408728     5.930335     5.735007     8.767954   \n",
       "50%       10.530301     5.877591     6.185873     5.938094     9.911805   \n",
       "75%       11.159306     6.899220     6.456987     6.148720    10.560220   \n",
       "max       14.643900     9.932115     7.921411     8.708396    12.812082   \n",
       "\n",
       "              FOXA1         MLPH  \n",
       "count   1904.000000  1904.000000  \n",
       "unique          NaN          NaN  \n",
       "top             NaN          NaN  \n",
       "freq            NaN          NaN  \n",
       "mean      10.800526    11.362384  \n",
       "std        1.754282     1.687555  \n",
       "min        5.184945     5.323652  \n",
       "25%       10.829777    11.042871  \n",
       "50%       11.367947    11.873967  \n",
       "75%       11.779545    12.396317  \n",
       "max       13.127682    14.432001  \n",
       "\n",
       "[11 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Read metabric dataset\n",
    "metabric = pd.read_csv(r\"../data/metabric_clinical_and_expression_data.csv\")\n",
    "\n",
    "# Store summary statistics\n",
    "metabric_summary = metabric.describe()\n",
    "metabric_summary\n",
    "\n",
    "metabric_summary = metabric.describe(include=\"all\")\n",
    "metabric_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method to_csv in module pandas.core.generic:\n",
      "\n",
      "to_csv(path_or_buf: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, sep: 'str' = ',', na_rep: 'str' = '', float_format: 'str | Callable | None' = None, columns: 'Sequence[Hashable] | None' = None, header: 'bool_t | list[str]' = True, index: 'bool_t' = True, index_label: 'IndexLabel | None' = None, mode: 'str' = 'w', encoding: 'str | None' = None, compression: 'CompressionOptions' = 'infer', quoting: 'int | None' = None, quotechar: 'str' = '\"', lineterminator: 'str | None' = None, chunksize: 'int | None' = None, date_format: 'str | None' = None, doublequote: 'bool_t' = True, escapechar: 'str | None' = None, decimal: 'str' = '.', errors: 'str' = 'strict', storage_options: 'StorageOptions' = None) -> 'str | None' method of pandas.core.frame.DataFrame instance\n",
      "    Write object to a comma-separated values (csv) file.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path_or_buf : str, path object, file-like object, or None, default None\n",
      "        String, path object (implementing os.PathLike[str]), or file-like\n",
      "        object implementing a write() function. If None, the result is\n",
      "        returned as a string. If a non-binary file object is passed, it should\n",
      "        be opened with `newline=''`, disabling universal newlines. If a binary\n",
      "        file object is passed, `mode` might need to contain a `'b'`.\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "    \n",
      "           Support for binary file objects was introduced.\n",
      "    \n",
      "    sep : str, default ','\n",
      "        String of length 1. Field delimiter for the output file.\n",
      "    na_rep : str, default ''\n",
      "        Missing data representation.\n",
      "    float_format : str, Callable, default None\n",
      "        Format string for floating point numbers. If a Callable is given, it takes\n",
      "        precedence over other numeric formatting parameters, like decimal.\n",
      "    columns : sequence, optional\n",
      "        Columns to write.\n",
      "    header : bool or list of str, default True\n",
      "        Write out the column names. If a list of strings is given it is\n",
      "        assumed to be aliases for the column names.\n",
      "    index : bool, default True\n",
      "        Write row names (index).\n",
      "    index_label : str or sequence, or False, default None\n",
      "        Column label for index column(s) if desired. If None is given, and\n",
      "        `header` and `index` are True, then the index names are used. A\n",
      "        sequence should be given if the object uses MultiIndex. If\n",
      "        False do not print fields for index names. Use index_label=False\n",
      "        for easier importing in R.\n",
      "    mode : str, default 'w'\n",
      "        Python write mode. The available write modes are the same as\n",
      "        :py:func:`open`.\n",
      "    encoding : str, optional\n",
      "        A string representing the encoding to use in the output file,\n",
      "        defaults to 'utf-8'. `encoding` is not supported if `path_or_buf`\n",
      "        is a non-binary file object.\n",
      "    compression : str or dict, default 'infer'\n",
      "        For on-the-fly compression of the output data. If 'infer' and 'path_or_buf' is\n",
      "        path-like, then detect compression from the following extensions: '.gz',\n",
      "        '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "        (otherwise no compression).\n",
      "        Set to ``None`` for no compression.\n",
      "        Can also be a dict with key ``'method'`` set\n",
      "        to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      "        key-value pairs are forwarded to\n",
      "        ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "        ``bz2.BZ2File``, ``zstandard.ZstdCompressor`` or\n",
      "        ``tarfile.TarFile``, respectively.\n",
      "        As an example, the following could be passed for faster compression and to create\n",
      "        a reproducible gzip archive:\n",
      "        ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      "    \n",
      "            .. versionadded:: 1.5.0\n",
      "                Added support for `.tar` files.\n",
      "    \n",
      "        .. versionchanged:: 1.0.0\n",
      "    \n",
      "           May now be a dict with key 'method' as compression mode\n",
      "           and other entries as additional compression options if\n",
      "           compression mode is 'zip'.\n",
      "    \n",
      "        .. versionchanged:: 1.1.0\n",
      "    \n",
      "           Passing compression options as keys in dict is\n",
      "           supported for compression modes 'gzip', 'bz2', 'zstd', and 'zip'.\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "    \n",
      "            Compression is supported for binary file objects.\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "    \n",
      "            Previous versions forwarded dict entries for 'gzip' to\n",
      "            `gzip.open` instead of `gzip.GzipFile` which prevented\n",
      "            setting `mtime`.\n",
      "    \n",
      "    quoting : optional constant from csv module\n",
      "        Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      "        then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      "        will treat them as non-numeric.\n",
      "    quotechar : str, default '\\\"'\n",
      "        String of length 1. Character used to quote fields.\n",
      "    lineterminator : str, optional\n",
      "        The newline character or character sequence to use in the output\n",
      "        file. Defaults to `os.linesep`, which depends on the OS in which\n",
      "        this method is called ('\\\\n' for linux, '\\\\r\\\\n' for Windows, i.e.).\n",
      "    \n",
      "        .. versionchanged:: 1.5.0\n",
      "    \n",
      "            Previously was line_terminator, changed for consistency with\n",
      "            read_csv and the standard library 'csv' module.\n",
      "    \n",
      "    chunksize : int or None\n",
      "        Rows to write at a time.\n",
      "    date_format : str, default None\n",
      "        Format string for datetime objects.\n",
      "    doublequote : bool, default True\n",
      "        Control quoting of `quotechar` inside a field.\n",
      "    escapechar : str, default None\n",
      "        String of length 1. Character used to escape `sep` and `quotechar`\n",
      "        when appropriate.\n",
      "    decimal : str, default '.'\n",
      "        Character recognized as decimal separator. E.g. use ',' for\n",
      "        European data.\n",
      "    errors : str, default 'strict'\n",
      "        Specifies how encoding and decoding errors are to be handled.\n",
      "        See the errors argument for :func:`open` for a full list\n",
      "        of options.\n",
      "    \n",
      "        .. versionadded:: 1.1.0\n",
      "    \n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "        URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "        forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "        details, and for more examples on storage options refer `here\n",
      "        <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "        highlight=storage_options#reading-writing-remote-files>`_.\n",
      "    \n",
      "        .. versionadded:: 1.2.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    None or str\n",
      "        If path_or_buf is None, returns the resulting csv format as a\n",
      "        string. Otherwise returns None.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    read_csv : Load a CSV file into a DataFrame.\n",
      "    to_excel : Write DataFrame to an Excel file.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      "    ...                    'mask': ['red', 'purple'],\n",
      "    ...                    'weapon': ['sai', 'bo staff']})\n",
      "    >>> df.to_csv(index=False)\n",
      "    'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      "    \n",
      "    Create 'out.zip' containing 'out.csv'\n",
      "    \n",
      "    >>> compression_opts = dict(method='zip',\n",
      "    ...                         archive_name='out.csv')  # doctest: +SKIP\n",
      "    >>> df.to_csv('out.zip', index=False,\n",
      "    ...           compression=compression_opts)  # doctest: +SKIP\n",
      "    \n",
      "    To write a csv file to a new folder or nested folder you will first\n",
      "    need to create it using either Pathlib or os:\n",
      "    \n",
      "    >>> from pathlib import Path  # doctest: +SKIP\n",
      "    >>> filepath = Path('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      "    >>> filepath.parent.mkdir(parents=True, exist_ok=True)  # doctest: +SKIP\n",
      "    >>> df.to_csv(filepath)  # doctest: +SKIP\n",
      "    \n",
      "    >>> import os  # doctest: +SKIP\n",
      "    >>> os.makedirs('folder/subfolder', exist_ok=True)  # doctest: +SKIP\n",
      "    >>> df.to_csv('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write summary statistics in csv and tsv\n",
    "\n",
    "help(metabric.to_csv)\n",
    "#metabric_summary.to_csv(\"metabric_summary.csv\")\n",
    "#metabric_summary.to_csv(\"metabric_summary.tsv\", sep = '\\t')\n",
    "#metabric_summary.to_csv(\"metabric_summary.csv\", columns = [\"Cohort\", \"Age_at_diagnosis\"])\n",
    "#metabric_summary.to_csv(\"metabric_summary.csv\", header = False)\n",
    "#metabric_summary.to_csv(\"~/Desktop/metabric_summary.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write an excel spreadsheet\n",
    "\n",
    "#help(metabric.to_excel)\n",
    "metabric_summary.to_excel(\"metabric_summary.xlsx\")\n",
    "\n",
    "#If: ModuleNotFoundError: No module named 'openpyxl'\n",
    "#pip3 install openpyxl --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "- Read the dataset `metabric_clinical_and_expression_data.csv` into a variable e.g. `metabric`.\n",
    "- Calculate the mean tumour size of patients grouped by vital status and tumour stage\n",
    "- Find the cohort of patients and tumour stage where the average expression of genes TP53 and FOXA1 is highest\n",
    "- Do patients with greater tumour size live longer? How about patients with greater tumour stage? How about greater Nottingham_prognostic_index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean tumour size of patients grouped by vital status and tumour stage\n",
    "\n",
    "import pandas as pd\n",
    "metabric = pd.read_csv(\"../data/metabric_clinical_and_expression_data.csv\")\n",
    "#help(metabric.groupby)\n",
    "#metabric.groupby(['Vital_status', 'Tumour_stage'])\n",
    "#metabric.groupby(['Vital_status', 'Tumour_stage']).mean()\n",
    "#metabric.groupby(['Vital_status', 'Tumour_stage']).mean()['Tumour_size']\n",
    "#metabric.groupby(['Vital_status', 'Tumour_stage']).size()\n",
    "#metabric.groupby(['Vital_status', 'Tumour_stage']).agg(['mean', 'size'])['Tumour_size']\n",
    "#metabric.groupby(['Vital_status', 'Tumour_stage', 'Radiotherapy'])['Tumour_size'].agg(['mean', 'size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the cohort of patients and tumour stage where the average expression of genes TP53 and FOXA1 is highest\n",
    "\n",
    "#metabric['TP53_FOXA1_mean'] = metabric[['TP53', 'FOXA1']].mean(axis=1)\n",
    "#metabric\n",
    "metabric.groupby(['Cohort', 'Tumour_stage']).agg(['mean', 'size'])['TP53_FOXA1_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do patients with greater tumour size live longer?\n",
    "metabric_dead = metabric[metabric['Vital_status'] == 'Died of Disease']\n",
    "metabric_dead\n",
    "\n",
    "metabric_dead[['Tumour_size', 'Survival_time']]\n",
    "metabric_dead['Tumour_size'].corr(metabric_dead['Survival_time'])\n",
    "help(metabric_dead['Tumour_size'].corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about patients with greater tumour stage? \n",
    "\n",
    "#metabric_dead[['Tumour_stage', 'Survival_time']]\n",
    "metabric_dead[['Tumour_stage', 'Survival_time']].groupby('Tumour_stage').agg(['mean', 'std', 'size'])\n",
    "\n",
    "#metabric_dead['Tumour_stage'].corr(metabric_dead['Survival_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about greater Nottingham_prognostic_index?\n",
    "# https://en.wikipedia.org/wiki/Nottingham_Prognostic_Index\n",
    "\n",
    "#metabric_dead[['Nottingham_prognostic_index', 'Survival_time']]\n",
    "metabric_dead['Nottingham_prognostic_index'].corr(metabric_dead['Survival_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 (bonus)\n",
    "\n",
    "Review the section on missing data presented in the lecture. Consulting the [user's guide section dedicated to missing data](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html) if necessary use the functionality provided by pandas to answer the following questions:\n",
    "\n",
    "- Which variables (columns) of the metabric dataset have missing data?\n",
    "- Find the patients ids who have missing tumour size and/or missing mutation count data. Which cohorts do they belong to?\n",
    "- For the patients identified to have missing tumour size data for each cohort, calculate the average tumour size of the patients with tumour size data available within the same cohort to fill in the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which variables (columns) of the metabric dataset have missing data?\n",
    "metabric.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the patients ids who have missing tumour size and/or missing mutation count data. Which cohorts do they belong to?\n",
    "#metabric[metabric['Tumour_size'].isna()]\n",
    "#metabric[metabric['Tumour_size'].isna()]['Cohort'].unique()\n",
    "\n",
    "#metabric[metabric['Mutation_count'].isna()]\n",
    "#metabric[metabric['Mutation_count'].isna()]['Cohort'].unique()\n",
    "\n",
    "metabric[(metabric['Tumour_size'].isna()) | (metabric['Mutation_count'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the patients identified to have missing tumour size data for each cohort, calculate the average tumour size of the patients with tumour size data available within the same cohort to fill in the missing data\n",
    "\n",
    "# Cohort 1\n",
    "metabric_c1 = metabric[metabric['Cohort'] == 1]\n",
    "metabric_c1[metabric_c1['Tumour_size'].isna()]\n",
    "metabric_c1[metabric_c1['Tumour_size'].notna()]\n",
    "metabric_c1[metabric_c1['Tumour_size'].notna()]['Tumour_size'].mean()\n",
    "mean_c1 = round(metabric_c1[metabric_c1['Tumour_size'].notna()]['Tumour_size'].mean(),1)\n",
    "mean_c1\n",
    "metabric_c1 = metabric_c1.fillna(value={'Tumour_size': mean_c1})\n",
    "metabric_c1[metabric_c1['Tumour_size'].isna()]\n",
    "metabric_c1[metabric_c1['Patient_ID'].isin([\"MB-0259\", \"MB-0284\", \"MB-0522\"])]\n",
    "# Validation of the absence of missingness\n",
    "metabric_c1['Tumour_size'].isnull().value_counts()\n",
    "\n",
    "# Cohort 3\n",
    "#metabric_c3 = metabric[metabric['Cohort'] == 3]\n",
    "#metabric_c3[metabric_c3['Tumour_size'].isna()]\n",
    "#mean_c3 = round(metabric_c3[metabric_c3['Tumour_size'].notna()]['Tumour_size'].mean(),1)\n",
    "#metabric_c3 = metabric_c3.fillna(value={'Tumour_size': mean_c3})\n",
    "\n",
    "# Cohort 5\n",
    "#metabric_c5 = metabric[metabric['Cohort'] == 5]\n",
    "#metabric_c5[metabric_c5['Tumour_size'].isna()]\n",
    "#mean_c5 = round(metabric_c5[metabric_c5['Tumour_size'].notna()]['Tumour_size'].mean(),1)\n",
    "#metabric_c5 = metabric_c5.fillna(value={'Tumour_size': mean_c5})\n",
    "\n",
    "\n",
    "### $$$ Bonus $$$ ### \n",
    "# Using what you have learnt in weeks 1 (intro) and 2 (pandas), \n",
    "# Write a function that takes an input dataframe and two columns e.g. \"Cohort\" and \"Tumour_size\"\n",
    "# and returns a new dataframe with the NaNs filled using the logic above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
