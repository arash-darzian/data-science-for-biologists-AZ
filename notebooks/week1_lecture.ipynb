{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 - Data handling\n",
    "\n",
    "The Python modules `pandas` and `numpy` are useful libraries to handle datasets and apply basic operations on them. \n",
    "\n",
    "Some of the things recapped in week 0 using native Python (e.g. accessing, working with and writing data files, and performing operations on them) can be easily achieved using `pandas` instead. `pandas` offers data structures and operations for manipulating different types of datasets - see [documentation](https://pandas.pydata.org/).\n",
    "\n",
    "We will only cover `pandas` today, however feel free to explore `numpy` in parallel at your own pace e.g. following [this tutorial](https://numpy.org/devdocs/user/quickstart.html) and combining it with continuing to learn `pandas`.\n",
    "\n",
    "\n",
    "### Aims\n",
    "\n",
    "- Gain familiarity to handle datasets using `pandas`\n",
    "    - Create, read and write data\n",
    "    - Select a subset of variables (columns)\n",
    "    - Filter rows based on their values\n",
    "    - Sort datasets\n",
    "    - Create new columns or modify existing ones\n",
    "    - Summarise and collapse values in one or more columns to a single summary value\n",
    "    - Handle missing data\n",
    "    - Merge datasets\n",
    "\n",
    "\n",
    "### Installing pandas\n",
    "\n",
    "The module `pandas` does not come by default as part of the default Python or Jupyter installations. In order to install it in your system, launch the Command prompt just like we saw in week 0 and run the following command: `pip install pandas --user`. Once the command finishes execution, `pandas` will be installed in your system\n",
    "\n",
    "**Note 1:** if you have any issues installing `pandas`, please get in touch with one of the trainers after the lecture\n",
    "\n",
    "**Note 2:** you can try the same to install the `numpy` module using the same approach\n",
    "\n",
    "\n",
    "### Loading pandas\n",
    "\n",
    "Once installed, you can import it e.g. using the alias `pd` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading datasets with `pandas`\n",
    "\n",
    "We are going to use the METABRIC dataset `metabric_clinical_and_expression_data.csv` containing information about breast cancer patients as highlighted in the recap materials from week 0.\n",
    "\n",
    "Pandas allows importing data from various file formats such as csv, xls, json, sql ... \n",
    "\n",
    "To read a csv file, use the method `.read_csv()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric = pd.read_csv(\"../data/metabric_clinical_and_expression_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metabric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you forget to include `../data/` above, or if you include it but your copy of the file is saved somewhere else, you will get an error that ends with a line like this: `FileNotFoundError: File b'metabric_clinical_and_expression_data.csv' does not exist`\n",
    "\n",
    "Generally, rows in a `DataFrame` are the **observations** (patients in the case of METABRIC) whereas columns are known as the observed **variables** (Cohort, Age_at_diagnosis ...). \n",
    "\n",
    "Looking at the column on the far left, you can see the row names of the DataFrame `metabric` assigned using the known 0-based indexing used in Python.\n",
    "\n",
    "Note that the `.read_csv()` method is not limited to reading csv files. For example, you can also read Tab Separated Value (TSV) files by adding the argument `sep='\\t'`.\n",
    "\n",
    "\n",
    "### Exploring data\n",
    "\n",
    "The pandas DataFrame object borrows features from the well-known R's `data.frame` or SQL's `table`. They are 2-dimensional tables whose columns can contain different data types (e.g. boolean, integer, float, categorical/factor). Both the rows and columns are indexed, and can be referred to by number or name.\n",
    "\n",
    "An index in a DataFrame refers to the position of an element in the data structure. Using the `.info()` method, we can view basic information about our DataFrame object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, our object is a `DataFrame` (or, to use the full name that Python uses to refer to it internally, a `pandas.core.frame.DataFrame`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(metabric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has 1904 rows (the patients) and 32 columns. The columns consist of integer, floats and strings (object). It uses almost 500 KB of memory.\n",
    "\n",
    "As mentioned, a DataFrame is a Python object or data structure, which means it can have **Attributes** and **Methods**.\n",
    "\n",
    "**Attributes** contain information about the object. You can access them to learn more about the contents of your DataFrame. To do this, use the object variable name `metabric` followed by the attribute name, separated by a `.`. Do not use any () to access attributes.\n",
    "\n",
    "For example, the types of data contained in the columns are stored in the `.dtypes` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the dimensions of your DataFrame using the `.shape` attribute. The first value is the number of rows, and the second the number of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The row and column names can be accessed using the attributes `.index` and `.columns` respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to transpose `metabric` use the attribute `T`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Methods** are functions that are associated with a DataFrame. Because they are functions, you do use () to call them, and can have arguments added inside the parentheses to control their behaviour. For example, the `.info()` command we executed previously was a method.\n",
    "\n",
    "The `.head()` method prints the first few rows of the table, while the `.tail()` method prints the last few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.describe()` method computes summary statistics for the columns (including the count, mean, median, and std):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general you can find which **Attributes** and **Methods** are available for your DataFrame using the function `dir()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(metabric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often want to calculate summary statistics grouped by subsets or attributes within fields of our data. For example, we might want to calculate the average survival time for patients with an advanced tumour stage.\n",
    "\n",
    "There are two ways to access columns in a DataFrame. The first is using the name of the DataFrame `metabric` followed by a `.` and then followed by the name of the column. The second is using square brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.Survival_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric['Survival_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute metrics on specific columns or on the entire DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric['Survival_time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric['Survival_time'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting columns and rows\n",
    "\n",
    "The [pandas cheat sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) can be very helpful for recalling basic pandas operations.\n",
    "\n",
    "To select rows and columns in a DataFrame, we use square brackets `[ ]`. There are two ways to do this: with **positional** indexing, which uses index numbers, and **label-based** indexing which uses column or row names.\n",
    "\n",
    "To select the first three rows using their numeric index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The colon `:` defines a range as we saw with slicing lists in week 1.\n",
    "\n",
    "To select one column using its name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric['Mutation_count']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! And we can combine the two like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric[:6]['Mutation_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However the following does not work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric[:3,'Mutation_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do **positional** indexing for both rows and columns, use `.iloc[]`. The first argument is the numeric index of the rows, and the second the numeric index of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.iloc[:3,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **label-based** indexing, use `.loc[]` with the column and row names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.loc[:3,\"Age_at_diagnosis\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: because the rows have numeric indices in this DataFrame, we may think that selecting rows with `.iloc[]` and `.loc[]` is same. As observed above, this is not the case.\n",
    "\n",
    "If you'd like to select more than one column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.loc[:3, ['Cohort', 'Chemotherapy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.loc[:3, 'Cohort':'Chemotherapy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metabric.loc[:5, 'Survival_time']\n",
    "# metabric.loc[:5, ['Cohort','Survival_status']]\n",
    "# metabric.loc[:5, 'Cohort':'Survival_status']\n",
    "# metabric.iloc[:5, 2]\n",
    "# metabric.iloc[:5, [0,3]]\n",
    "# metabric.iloc[:5, 0:3]\n",
    "# metabric[:5].Survival_status\n",
    "# metabric[:5]['Survival_status']\n",
    "# metabric[:5][['Cohort','Survival_status']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering rows\n",
    "\n",
    "You can choose rows from a DataFrame that match some specified criteria. The criteria are based on values of variables and can make use of comparison operators such as `==`, `>`, `<` and `!=`.\n",
    "\n",
    "For example, to filter `metabric` so that it only contains observations for those patients who died of breast cancer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric[metabric.Vital_status==\"Died of Disease\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To filter based on more than one condition, you can use the operators `&` (and), `|` (or). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.Vital_status.value_counts()\n",
    "metabric[(metabric.Vital_status==\"Died of Disease\") | (metabric.Age_at_diagnosis>70)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categorical variables e.g. `Vital_status` or `Cohort`, it may be useful to count how many occurrences there is for each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric['Vital_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric['Vital_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To filter by more than one category, use the `.isin()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric[metabric.Vital_status.isin(['Died of Disease', 'Died of Other Causes'])].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cancer studies, a cohort is a group of individuals who share one or more characteristics, such as having been diagnosed with a specific type of cancer or having a particular risk factor for cancer. A cohort study in cancer research typically involves following a group of individuals with similar characteristics over time to determine the incidence of cancer or other outcomes of interest.\n",
    "\n",
    "A cancer cohort study may involve collecting data on the exposure of the cohort members to various risk factors, such as smoking, environmental toxins, or genetic predisposition to cancer. The cohort members are then followed up over time to determine the incidence of cancer and other health outcomes. The study may also involve comparing the incidence of cancer in the cohort with that in a control group of individuals who do not share the same characteristics as the cohort, such as not having the same risk factors for cancer.\n",
    "\n",
    "One type of cohort study that is often used in cancer research is a prospective cohort study, in which data on the exposure to risk factors and the occurrence of cancer are collected over time. This type of study can provide valuable information on the temporal relationship between risk factors and cancer outcomes. Another type of cohort study is a retrospective cohort study, in which data on risk factors and cancer outcomes are collected retrospectively from existing records.\n",
    "\n",
    "Cancer cohort studies are important in identifying risk factors for cancer and in understanding the natural history and prognosis of different types of cancer. They can also provide valuable information for developing and evaluating cancer prevention and treatment strategies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few examples of AstraZeneca's cancer drugs:\n",
    "\n",
    "Tagrisso (osimertinib): This is a targeted therapy drug used to treat non-small cell lung cancer (NSCLC) that has a specific mutation in the EGFR gene. It works by inhibiting the growth and spread of cancer cells.\n",
    "\n",
    "Lynparza (olaparib): This is a PARP inhibitor used to treat several types of cancer, including ovarian, breast, and pancreatic cancer. It works by preventing cancer cells from repairing damaged DNA, leading to their death.\n",
    "\n",
    "Imfinzi (durvalumab): This is an immunotherapy drug used to treat several types of cancer, including lung cancer and bladder cancer. It works by helping the body's immune system to recognize and attack cancer cells.\n",
    "\n",
    "Calquence (acalabrutinib): This is a targeted therapy drug used to treat mantle cell lymphoma, a type of blood cancer. It works by blocking a specific protein that is necessary for the growth and survival of cancer cells.\n",
    "\n",
    "Faslodex (fulvestrant): This is a hormone therapy drug used to treat hormone receptor-positive breast cancer. It works by blocking the effects of estrogen on cancer cells, which slows or stops their growth."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A targeted drug is a type of medication that is designed to specifically target and interact with a particular molecule or pathway that is involved in the development or progression of a disease. These drugs are often used in the treatment of cancer, but they can also be used in the treatment of other diseases such as autoimmune disorders, viral infections, and genetic disorders.\n",
    "\n",
    "In cancer treatment, targeted drugs work by blocking the growth and spread of cancer cells. Unlike traditional chemotherapy, which affects all rapidly dividing cells in the body, targeted drugs are designed to specifically target cancer cells while minimizing damage to healthy cells. Targeted drugs can be used alone or in combination with other treatments, such as chemotherapy or radiation therapy.\n",
    "\n",
    "There are several types of targeted drugs, including monoclonal antibodies, small molecule inhibitors, and immunotherapies. Monoclonal antibodies are proteins that are designed to bind to specific molecules on the surface of cancer cells, triggering an immune response to attack and destroy the cancer cells. Small molecule inhibitors are drugs that are designed to interact with specific enzymes or proteins inside the cancer cell, preventing it from dividing and growing. Immunotherapies are drugs that stimulate the immune system to recognize and attack cancer cells.\n",
    "\n",
    "Targeted drugs have revolutionized cancer treatment and have provided new options for patients who previously had limited treatment options. However, like all medications, targeted drugs can have side effects, and not all patients will respond to them. It is important to work closely with a healthcare provider to determine if a targeted drug is an appropriate treatment option and to monitor for potential side effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric['Cohort'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! To tabulate two categorical variables just like `table` in R, use the function `.crosstab()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(metabric['Vital_status'], metabric['Cohort'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define new columns\n",
    "\n",
    "To obtain the age of the patient today `Age_today` (new column) based on the `Age_at_diagnosis` (years) and the `Survival_time` (days), you can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric['Age_today'] = metabric['Age_at_diagnosis'] + metabric['Survival_time']/365\n",
    "metabric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort data\n",
    "\n",
    "To sort the entire DataFrame according to one of the columns, we can use the `.sort_values()` method. We can store the sorted DataFrame using a new variable name such as `metabric_sorted`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric_sorted = metabric.sort_values('Tumour_size')\n",
    "metabric_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric_sorted.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric_sorted.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also sort the DataFrame in descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric_sorted = metabric.sort_values('Tumour_size', ascending=False)\n",
    "metabric_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric_sorted = metabric.sort_values(['Vital_status', 'Survival_time'], ascending=False)\n",
    "metabric_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data\n",
    "\n",
    "Pandas primarily uses `NaN` to represent missing data, which are by default not included in computations.\n",
    "\n",
    "The `.info()` method shown above already gave us a way to find columns containing missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the locations where values are missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(metabric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To drop any rows containing at least one column with missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, from the other way around, to rather remove columns with at least one row with missing data, you need to use the 'axis' argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define in which columns to look for missing values before dropping the row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.dropna(subset = [\"Tumour_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.dropna(subset = [\"Tumour_size\", \"Tumour_stage\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.fillna(value={'Tumour_size':0, 'Tumour_stage':5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping\n",
    "\n",
    "Grouping patients by Cohort and then applying the `.mean()` function to the resulting groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.groupby('Cohort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.groupby('Cohort').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping by multiple columns forms a hierarchical index, and again we can apply the `.mean()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric.groupby(['Cohort', 'Vital_status']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting\n",
    "\n",
    "In some cases, you may want to re-structure your existing DataFrame. The function `.pivot_table()` is useful for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = pd.DataFrame({'A': ['one', 'one', 'two', 'three'] * 3, 'B': ['A', 'B', 'C'] * 4, 'C': ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2, 'D': np.random.randn(12), 'E': np.random.randn(12)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge datasets\n",
    "\n",
    "You can concatenate DataFrames using the function `concat()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric_cohort1 = metabric[metabric[\"Cohort\"]==1]\n",
    "metabric_cohort1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric_cohort2 = metabric[metabric[\"Cohort\"]==2]\n",
    "metabric_cohort2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([metabric_cohort1,metabric_cohort2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or join datasets using the function `.merge()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key': ['foo', 'foo'], 'lval': [1, 2]})\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = pd.DataFrame({'key': ['foo', 'foo'], 'rval': [4, 5]})\n",
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left, right, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A final example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key': ['foo', 'bar'], 'lval': [1, 2]})\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = pd.DataFrame({'key': ['foo', 'bar'], 'rval': [4, 5]})\n",
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left, right, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "1. Write python commands using pandas to learn how to output tables as follows:\n",
    "\n",
    "    - Read the dataset `metabric_clinical_and_expression_data.csv` and store its summary statistics into a new variable called `metabric_summary`.\n",
    "    - Just like the `.read_csv()` method allows reading data from a file, `pandas` provides a `.to_csv()` method to write `DataFrames` to files. Write your summary statistics object into a file called `metabric_summary.csv`. You can use `help(metabric.to_csv)` to get information on how to use this function.\n",
    "    - Use the help information to modify the previous step so that you can generate a Tab Separated Value (TSV) file instead \n",
    "    - Similarly, explore the method `to_excel()` to output an excel spreadsheet containing summary statistics\n",
    "\n",
    "\n",
    "2. Write python commands to perform basic statistics in the metabric dataset and answer the following questions:\n",
    "\n",
    "    - Read the dataset `metabric_clinical_and_expression_data.csv` into a variable e.g. `metabric`.\n",
    "    - Calculate mean tumour size of patients grouped by vital status and tumour stage\n",
    "    - Find the cohort of patients and tumour stage where the average expression of genes TP53 and FOXA1 is the highest\n",
    "    - Do patients with greater tumour size live longer? How about patients with greater tumour stage? How about greater Nottingham_prognostic_index?\n",
    "\n",
    "\n",
    "3. Review the section on missing data presented in the lecture. Consulting the [user's guide section dedicated to missing data](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html) and any other materials as necessary use the functionality provided by pandas to answer the following questions:\n",
    "\n",
    "    - Which variables (columns) of the metabric dataset have missing data?\n",
    "    - Find the patients ids who have missing tumour size and/or missing mutation count data. Which cohorts do they belong to?\n",
    "    - For the patients identified to have missing tumour size data for each cohort, calculate the average tumour size of the patients with tumour size data available within the same cohort to fill in the missing data\n",
    "\n",
    "\n",
    "4. (Bonus) Try out pandas in a dataset of your own work or from literature/resources you have read/used recently and share with a colleague / rest of the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Age_at_diagnosis</th>\n",
       "      <th>Survival_time</th>\n",
       "      <th>Survival_status</th>\n",
       "      <th>Vital_status</th>\n",
       "      <th>Chemotherapy</th>\n",
       "      <th>Radiotherapy</th>\n",
       "      <th>Tumour_size</th>\n",
       "      <th>Tumour_stage</th>\n",
       "      <th>...</th>\n",
       "      <th>Integrative_cluster</th>\n",
       "      <th>Mutation_count</th>\n",
       "      <th>ESR1</th>\n",
       "      <th>ERBB2</th>\n",
       "      <th>PGR</th>\n",
       "      <th>TP53</th>\n",
       "      <th>PIK3CA</th>\n",
       "      <th>GATA3</th>\n",
       "      <th>FOXA1</th>\n",
       "      <th>MLPH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1904</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904</td>\n",
       "      <td>1903</td>\n",
       "      <td>1904</td>\n",
       "      <td>1904</td>\n",
       "      <td>1884.000000</td>\n",
       "      <td>1403.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1904</td>\n",
       "      <td>1859.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "      <td>1904.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>MB-0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DECEASED</td>\n",
       "      <td>Living</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1103</td>\n",
       "      <td>801</td>\n",
       "      <td>1508</td>\n",
       "      <td>1137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.643908</td>\n",
       "      <td>61.087054</td>\n",
       "      <td>125.121324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.238726</td>\n",
       "      <td>1.750535</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.697687</td>\n",
       "      <td>9.607824</td>\n",
       "      <td>10.765364</td>\n",
       "      <td>6.237203</td>\n",
       "      <td>6.197967</td>\n",
       "      <td>5.970097</td>\n",
       "      <td>9.502910</td>\n",
       "      <td>10.800526</td>\n",
       "      <td>11.362384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.228615</td>\n",
       "      <td>12.978711</td>\n",
       "      <td>76.334148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.160976</td>\n",
       "      <td>0.628999</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.058778</td>\n",
       "      <td>2.133827</td>\n",
       "      <td>1.357359</td>\n",
       "      <td>1.020871</td>\n",
       "      <td>0.401864</td>\n",
       "      <td>0.352549</td>\n",
       "      <td>1.502636</td>\n",
       "      <td>1.754282</td>\n",
       "      <td>1.687555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.930000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.217238</td>\n",
       "      <td>6.372949</td>\n",
       "      <td>4.860645</td>\n",
       "      <td>5.201128</td>\n",
       "      <td>5.158697</td>\n",
       "      <td>5.277722</td>\n",
       "      <td>5.184945</td>\n",
       "      <td>5.323652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.375000</td>\n",
       "      <td>60.825000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.092992</td>\n",
       "      <td>9.969681</td>\n",
       "      <td>5.408728</td>\n",
       "      <td>5.930335</td>\n",
       "      <td>5.735007</td>\n",
       "      <td>8.767954</td>\n",
       "      <td>10.829777</td>\n",
       "      <td>11.042871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>61.770000</td>\n",
       "      <td>115.616667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.252166</td>\n",
       "      <td>10.530301</td>\n",
       "      <td>5.877591</td>\n",
       "      <td>6.185873</td>\n",
       "      <td>5.938094</td>\n",
       "      <td>9.911805</td>\n",
       "      <td>11.367947</td>\n",
       "      <td>11.873967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>70.592500</td>\n",
       "      <td>184.716667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.268331</td>\n",
       "      <td>11.159306</td>\n",
       "      <td>6.899220</td>\n",
       "      <td>6.456987</td>\n",
       "      <td>6.148720</td>\n",
       "      <td>10.560220</td>\n",
       "      <td>11.779545</td>\n",
       "      <td>12.396317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>96.290000</td>\n",
       "      <td>355.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>13.265184</td>\n",
       "      <td>14.643900</td>\n",
       "      <td>9.932115</td>\n",
       "      <td>7.921411</td>\n",
       "      <td>8.708396</td>\n",
       "      <td>12.812082</td>\n",
       "      <td>13.127682</td>\n",
       "      <td>14.432001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_ID       Cohort  Age_at_diagnosis  Survival_time  \\\n",
       "count        1904  1904.000000       1904.000000    1904.000000   \n",
       "unique       1904          NaN               NaN            NaN   \n",
       "top       MB-0000          NaN               NaN            NaN   \n",
       "freq            1          NaN               NaN            NaN   \n",
       "mean          NaN     2.643908         61.087054     125.121324   \n",
       "std           NaN     1.228615         12.978711      76.334148   \n",
       "min           NaN     1.000000         21.930000       0.000000   \n",
       "25%           NaN     1.000000         51.375000      60.825000   \n",
       "50%           NaN     3.000000         61.770000     115.616667   \n",
       "75%           NaN     3.000000         70.592500     184.716667   \n",
       "max           NaN     5.000000         96.290000     355.200000   \n",
       "\n",
       "       Survival_status Vital_status Chemotherapy Radiotherapy  Tumour_size  \\\n",
       "count             1904         1903         1904         1904  1884.000000   \n",
       "unique               2            3            2            2          NaN   \n",
       "top           DECEASED       Living           NO          YES          NaN   \n",
       "freq              1103          801         1508         1137          NaN   \n",
       "mean               NaN          NaN          NaN          NaN    26.238726   \n",
       "std                NaN          NaN          NaN          NaN    15.160976   \n",
       "min                NaN          NaN          NaN          NaN     1.000000   \n",
       "25%                NaN          NaN          NaN          NaN    17.000000   \n",
       "50%                NaN          NaN          NaN          NaN    23.000000   \n",
       "75%                NaN          NaN          NaN          NaN    30.000000   \n",
       "max                NaN          NaN          NaN          NaN   182.000000   \n",
       "\n",
       "        Tumour_stage  ...  Integrative_cluster  Mutation_count         ESR1  \\\n",
       "count    1403.000000  ...                 1904     1859.000000  1904.000000   \n",
       "unique           NaN  ...                   11             NaN          NaN   \n",
       "top              NaN  ...                    8             NaN          NaN   \n",
       "freq             NaN  ...                  289             NaN          NaN   \n",
       "mean        1.750535  ...                  NaN        5.697687     9.607824   \n",
       "std         0.628999  ...                  NaN        4.058778     2.133827   \n",
       "min         0.000000  ...                  NaN        1.000000     5.217238   \n",
       "25%         1.000000  ...                  NaN        3.000000     8.092992   \n",
       "50%         2.000000  ...                  NaN        5.000000    10.252166   \n",
       "75%         2.000000  ...                  NaN        7.000000    11.268331   \n",
       "max         4.000000  ...                  NaN       80.000000    13.265184   \n",
       "\n",
       "              ERBB2          PGR         TP53       PIK3CA        GATA3  \\\n",
       "count   1904.000000  1904.000000  1904.000000  1904.000000  1904.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      10.765364     6.237203     6.197967     5.970097     9.502910   \n",
       "std        1.357359     1.020871     0.401864     0.352549     1.502636   \n",
       "min        6.372949     4.860645     5.201128     5.158697     5.277722   \n",
       "25%        9.969681     5.408728     5.930335     5.735007     8.767954   \n",
       "50%       10.530301     5.877591     6.185873     5.938094     9.911805   \n",
       "75%       11.159306     6.899220     6.456987     6.148720    10.560220   \n",
       "max       14.643900     9.932115     7.921411     8.708396    12.812082   \n",
       "\n",
       "              FOXA1         MLPH  \n",
       "count   1904.000000  1904.000000  \n",
       "unique          NaN          NaN  \n",
       "top             NaN          NaN  \n",
       "freq            NaN          NaN  \n",
       "mean      10.800526    11.362384  \n",
       "std        1.754282     1.687555  \n",
       "min        5.184945     5.323652  \n",
       "25%       10.829777    11.042871  \n",
       "50%       11.367947    11.873967  \n",
       "75%       11.779545    12.396317  \n",
       "max       13.127682    14.432001  \n",
       "\n",
       "[11 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method to_csv in module pandas.core.generic:\n",
      "\n",
      "to_csv(path_or_buf: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, sep: 'str' = ',', na_rep: 'str' = '', float_format: 'str | Callable | None' = None, columns: 'Sequence[Hashable] | None' = None, header: 'bool_t | list[str]' = True, index: 'bool_t' = True, index_label: 'IndexLabel | None' = None, mode: 'str' = 'w', encoding: 'str | None' = None, compression: 'CompressionOptions' = 'infer', quoting: 'int | None' = None, quotechar: 'str' = '\"', lineterminator: 'str | None' = None, chunksize: 'int | None' = None, date_format: 'str | None' = None, doublequote: 'bool_t' = True, escapechar: 'str | None' = None, decimal: 'str' = '.', errors: 'str' = 'strict', storage_options: 'StorageOptions' = None) -> 'str | None' method of pandas.core.frame.DataFrame instance\n",
      "    Write object to a comma-separated values (csv) file.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path_or_buf : str, path object, file-like object, or None, default None\n",
      "        String, path object (implementing os.PathLike[str]), or file-like\n",
      "        object implementing a write() function. If None, the result is\n",
      "        returned as a string. If a non-binary file object is passed, it should\n",
      "        be opened with `newline=''`, disabling universal newlines. If a binary\n",
      "        file object is passed, `mode` might need to contain a `'b'`.\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "    \n",
      "           Support for binary file objects was introduced.\n",
      "    \n",
      "    sep : str, default ','\n",
      "        String of length 1. Field delimiter for the output file.\n",
      "    na_rep : str, default ''\n",
      "        Missing data representation.\n",
      "    float_format : str, Callable, default None\n",
      "        Format string for floating point numbers. If a Callable is given, it takes\n",
      "        precedence over other numeric formatting parameters, like decimal.\n",
      "    columns : sequence, optional\n",
      "        Columns to write.\n",
      "    header : bool or list of str, default True\n",
      "        Write out the column names. If a list of strings is given it is\n",
      "        assumed to be aliases for the column names.\n",
      "    index : bool, default True\n",
      "        Write row names (index).\n",
      "    index_label : str or sequence, or False, default None\n",
      "        Column label for index column(s) if desired. If None is given, and\n",
      "        `header` and `index` are True, then the index names are used. A\n",
      "        sequence should be given if the object uses MultiIndex. If\n",
      "        False do not print fields for index names. Use index_label=False\n",
      "        for easier importing in R.\n",
      "    mode : str, default 'w'\n",
      "        Python write mode. The available write modes are the same as\n",
      "        :py:func:`open`.\n",
      "    encoding : str, optional\n",
      "        A string representing the encoding to use in the output file,\n",
      "        defaults to 'utf-8'. `encoding` is not supported if `path_or_buf`\n",
      "        is a non-binary file object.\n",
      "    compression : str or dict, default 'infer'\n",
      "        For on-the-fly compression of the output data. If 'infer' and 'path_or_buf' is\n",
      "        path-like, then detect compression from the following extensions: '.gz',\n",
      "        '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "        (otherwise no compression).\n",
      "        Set to ``None`` for no compression.\n",
      "        Can also be a dict with key ``'method'`` set\n",
      "        to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      "        key-value pairs are forwarded to\n",
      "        ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "        ``bz2.BZ2File``, ``zstandard.ZstdCompressor`` or\n",
      "        ``tarfile.TarFile``, respectively.\n",
      "        As an example, the following could be passed for faster compression and to create\n",
      "        a reproducible gzip archive:\n",
      "        ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      "    \n",
      "            .. versionadded:: 1.5.0\n",
      "                Added support for `.tar` files.\n",
      "    \n",
      "        .. versionchanged:: 1.0.0\n",
      "    \n",
      "           May now be a dict with key 'method' as compression mode\n",
      "           and other entries as additional compression options if\n",
      "           compression mode is 'zip'.\n",
      "    \n",
      "        .. versionchanged:: 1.1.0\n",
      "    \n",
      "           Passing compression options as keys in dict is\n",
      "           supported for compression modes 'gzip', 'bz2', 'zstd', and 'zip'.\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "    \n",
      "            Compression is supported for binary file objects.\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "    \n",
      "            Previous versions forwarded dict entries for 'gzip' to\n",
      "            `gzip.open` instead of `gzip.GzipFile` which prevented\n",
      "            setting `mtime`.\n",
      "    \n",
      "    quoting : optional constant from csv module\n",
      "        Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      "        then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      "        will treat them as non-numeric.\n",
      "    quotechar : str, default '\\\"'\n",
      "        String of length 1. Character used to quote fields.\n",
      "    lineterminator : str, optional\n",
      "        The newline character or character sequence to use in the output\n",
      "        file. Defaults to `os.linesep`, which depends on the OS in which\n",
      "        this method is called ('\\\\n' for linux, '\\\\r\\\\n' for Windows, i.e.).\n",
      "    \n",
      "        .. versionchanged:: 1.5.0\n",
      "    \n",
      "            Previously was line_terminator, changed for consistency with\n",
      "            read_csv and the standard library 'csv' module.\n",
      "    \n",
      "    chunksize : int or None\n",
      "        Rows to write at a time.\n",
      "    date_format : str, default None\n",
      "        Format string for datetime objects.\n",
      "    doublequote : bool, default True\n",
      "        Control quoting of `quotechar` inside a field.\n",
      "    escapechar : str, default None\n",
      "        String of length 1. Character used to escape `sep` and `quotechar`\n",
      "        when appropriate.\n",
      "    decimal : str, default '.'\n",
      "        Character recognized as decimal separator. E.g. use ',' for\n",
      "        European data.\n",
      "    errors : str, default 'strict'\n",
      "        Specifies how encoding and decoding errors are to be handled.\n",
      "        See the errors argument for :func:`open` for a full list\n",
      "        of options.\n",
      "    \n",
      "        .. versionadded:: 1.1.0\n",
      "    \n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "        URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "        forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "        details, and for more examples on storage options refer `here\n",
      "        <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "        highlight=storage_options#reading-writing-remote-files>`_.\n",
      "    \n",
      "        .. versionadded:: 1.2.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    None or str\n",
      "        If path_or_buf is None, returns the resulting csv format as a\n",
      "        string. Otherwise returns None.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    read_csv : Load a CSV file into a DataFrame.\n",
      "    to_excel : Write DataFrame to an Excel file.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      "    ...                    'mask': ['red', 'purple'],\n",
      "    ...                    'weapon': ['sai', 'bo staff']})\n",
      "    >>> df.to_csv(index=False)\n",
      "    'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      "    \n",
      "    Create 'out.zip' containing 'out.csv'\n",
      "    \n",
      "    >>> compression_opts = dict(method='zip',\n",
      "    ...                         archive_name='out.csv')  # doctest: +SKIP\n",
      "    >>> df.to_csv('out.zip', index=False,\n",
      "    ...           compression=compression_opts)  # doctest: +SKIP\n",
      "    \n",
      "    To write a csv file to a new folder or nested folder you will first\n",
      "    need to create it using either Pathlib or os:\n",
      "    \n",
      "    >>> from pathlib import Path  # doctest: +SKIP\n",
      "    >>> filepath = Path('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      "    >>> filepath.parent.mkdir(parents=True, exist_ok=True)  # doctest: +SKIP\n",
      "    >>> df.to_csv(filepath)  # doctest: +SKIP\n",
      "    \n",
      "    >>> import os  # doctest: +SKIP\n",
      "    >>> os.makedirs('folder/subfolder', exist_ok=True)  # doctest: +SKIP\n",
      "    >>> df.to_csv('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
